{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os,glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir,makedirs\n",
    "from os.path import isfile,join\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "final_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checked If processed_images folder is exist or not\n",
    "# if not os.path.exists('./processed_images'):\n",
    "#             os.mkdir('./processed_images')\n",
    "for folder_index in range(10):\n",
    "    path = 'audio_spectograms/'+str(folder_index)\n",
    "#     if not os.path.exists('./processed_images/'+str(folder_index)):\n",
    "#             os.mkdir('./processed_images/'+str(folder_index))\n",
    "#     else:\n",
    "#             print('Images are already preprocessed!')\n",
    "#             sys.exit(0)  \n",
    "    for image_file in os.listdir(path):\n",
    "        #if processed_images directory exists, then save the image in that directory\n",
    "        image = cv2.imread(os.path.join(path,image_file))\n",
    "        gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        resize = cv2.resize(gray,(256,256))\n",
    "        #convert image to float32\n",
    "        resize = np.asarray(resize).astype(np.float32)\n",
    "        normalize = resize/255.0\n",
    "        #cv2.imwrite('.\\processed_images\\\\'+str(folder_index)+'\\\\'+image_file,normalize)\n",
    "        #append normalize photos and their labels to the list\n",
    "        final_list.append([normalize,int(image_file.split('-')[1])]) \n",
    "        #print normalize part from list\n",
    "       \n",
    "    # print(final_list)\n",
    "    \n",
    "          \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "y = [i[1] for i in final_list] #labels-class\n",
    "x = [i[0] for i in final_list] #features-image\n",
    "x = np.asarray(x).astype(np.float32)\n",
    "y = np.array(y)\n",
    "x_train,x_temp,y_train,y_temp = train_test_split(x,y,train_size = 0.8)\n",
    "x_test,x_val,y_test,y_val = train_test_split(x_temp,y_temp,test_size=0.5)\n",
    "# print(len(x_train))\n",
    "# print(len(x_test))\n",
    "# print(len(x_val))\n",
    "model.add(tf.keras.layers.Conv2D(32,\n",
    "                                 kernel_size=(3,3),strides=(1,2),\n",
    "                                 padding=\"same\",activation=\"relu\",\n",
    "                                 input_shape=(256,256,1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(tf.keras.layers.Conv2D(64,\n",
    "                                 kernel_size=(3,3),strides=(1,2),\n",
    "                                 padding=\"same\",activation=\"relu\"\n",
    "                                 ))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(64,activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(64,activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.optimizers.Adam(),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"Accuracy\"])\n",
    "results = model.fit(x_train,y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=20,verbose=1,\n",
    "                    validation_data=(x_val,y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
